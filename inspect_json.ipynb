{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Legacy version for adding classes to MS COCO JSON file!!! \n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CATEGORY INFORMATION\n",
    "### !!! NEED HELP FOR MATCHING THE CLASSES IN VOT2016 TO THEIR CORRESPONDING ONES IN MS-COCO !!! ### \n",
    "### Legend ###\n",
    "### * --> Will be defined into Mask R-CNN as a new category\n",
    "### ! --> Might be some issues with the assignment, they have to be rechecked\n",
    "dict_of_categories = {'fish1': 91, 'fish2': 91, 'fish3': 91,\n",
    "                      'fish4': 91, 'matrix': 92,  'shaking': 92,\n",
    "                      'singer3': 92, 'soccer1': 92, 'soldier': 92}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['licenses', 'info', 'categories', 'annotations', 'images'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_dir = \"Datasets/coco/annotations_old/instances_train2014 (copy).json\"\n",
    "\n",
    "minival2014 = json.load(open(json_dir))\n",
    "\n",
    "minival2014.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minival2014['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds the classes\n",
    "# minival2014['categories'].append({'id': 91, 'name': 'fish', 'supercategory': 'animal'})\n",
    "# minival2014['categories'].append({'id': 92, 'name': 'face', 'supercategory': 'person'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows the added class at the bottom.\n",
    "# minival2014['images'].pop()\n",
    "# (minival2014['images'][-20:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isjpg(string):\n",
    "    if string[-4:]==\".jpg\":\n",
    "        return True \n",
    "    \n",
    "def ispng(string):\n",
    "    if string[-4:]==\".png\":\n",
    "        return True \n",
    "    \n",
    "def DateCaptured():\n",
    "    dt = str(datetime.datetime.now())\n",
    "    date, time = dt.split()\n",
    "    time = time.split(\".\")[0]\n",
    "    return date+\" \"+time\n",
    "\n",
    "def coco_bbox_creator(x, y):\n",
    "    x = list(map(lambda x: float(x), x))\n",
    "    y = list(map(lambda x: float(x), y))\n",
    "    x_min = min(x)\n",
    "    y_min = min(y)\n",
    "    w = max(x) - x_min\n",
    "    h = max(y) - y_min\n",
    "    return [x_min, y_min, w, h]\n",
    "\n",
    "def PolyArea(x,y):\n",
    "    return 0.5*np.abs(np.dot(x,np.roll(y,1))-np.dot(y,np.roll(x,1)))\n",
    "\n",
    "dataset_dir = \"/home/mspr/Desktop/Mask_RCNN/Datasets/\"  # Will be changed with argparse, includes directories for video names and corresponding frames inside\n",
    "train = \"train/\"                                                # train\n",
    "dataset_seg_dir = \"GT_segmentation/\" # one indexed version for providing segmentation data.\n",
    "\n",
    "source_dataset_name = os.path.join(dataset_dir, \"VOT2016/\" , train)\n",
    "source_dataset_seg_loc = os.path.join(dataset_dir, \"VOT2016/\" , dataset_seg_dir)\n",
    "target_dataset_name = os.path.join(dataset_dir, \"coco/train2014/\")\n",
    "\n",
    "ground_truth_bbox = \"groundtruth.txt\"\n",
    "\n",
    "id_counter = 600000\n",
    "\n",
    "all_video_names = [folder for folder in os.listdir(source_dataset_name) if os.path.isdir(os.path.join(source_dataset_name, folder))] \n",
    "\n",
    "# Change: all_video_names --> dict_of_categories.keys()\n",
    "for video_name in dict_of_categories.keys():\n",
    "    all_frame_names = [frame for frame in os.listdir(os.path.join(source_dataset_name,\n",
    "                                                                  video_name)) if isjpg(os.path.join(source_dataset_name, video_name, frame))]\n",
    "    all_frame_names = sorted(all_frame_names)\n",
    "    all_seg_frame_names = [frame for frame in os.listdir(os.path.join(source_dataset_seg_loc,\n",
    "                                                                      video_name)) if ispng(os.path.join(source_dataset_seg_loc, video_name, frame))]\n",
    "    all_seg_frame_names = sorted(all_seg_frame_names)\n",
    "    \n",
    "    # bbox\n",
    "    bbox_info_file = os.path.join(source_dataset_name, video_name, ground_truth_bbox)\n",
    "    with open(bbox_info_file) as f:\n",
    "        all_bboxes = f.read().split()       \n",
    "        \n",
    "    for d, frame_name in enumerate(all_frame_names):\n",
    "            \n",
    "        # Date captured\n",
    "        date_captured = DateCaptured()\n",
    "        \n",
    "        # Copying to the COCO Dataset Directory in an appropiate format.\n",
    "        # Filename and ID will be collected from here.\n",
    "        if id_counter<1000000:\n",
    "            frame_file_name = \"COCO_train2014_000000\"+str(id_counter)+\".jpg\"\n",
    "        elif (id_counter>=1000000 or id_counter<=10000000):\n",
    "            frame_file_name = \"COCO_train2014_00000\"+str(id_counter)+\".jpg\"\n",
    "       \n",
    "        image = io.imread(os.path.join(source_dataset_name, video_name, frame_name))\n",
    "\n",
    "        if os.path.isfile(os.path.join(target_dataset_name, frame_file_name))==False:\n",
    "            io.imsave(os.path.join(target_dataset_name, frame_file_name), image)\n",
    "        \n",
    "        # License tag at random\n",
    "        license = np.random.randint(8)\n",
    "        \n",
    "        # Getting image width and height\n",
    "        height = image.shape[1]\n",
    "        width = image.shape[0]\n",
    "\n",
    "        # URL Information is unknown\n",
    "        url = 'n/a'\n",
    "        \n",
    "        # Appending relevant information to images section\n",
    "        minival2014['images'].append({'date_captured': date_captured, 'file_name': frame_file_name, \n",
    "                              'height': height, 'id': id_counter, 'license': license, 'flickr_url': url, \n",
    "                              'width': width, 'coco_url': url})\n",
    "\n",
    "        # bbox operations\n",
    "        coords = np.array(all_bboxes[d].split(\",\")).reshape((-1, 2))\n",
    "        x, y = coords[:,0], coords[:,1]\n",
    "        xywh = coco_bbox_creator(x, y)\n",
    "        \n",
    "        # Category ID \n",
    "        # Create a dictionary where the keys will be video names and \n",
    "        # values will be category id's. Then calling this dictionary\n",
    "        # appropiately will output the category id. \n",
    "        # E.g --> dict['fish1'] = 91\n",
    "        category_id = 91\n",
    "        \n",
    "        # id\n",
    "        annot_id = 300001\n",
    "\n",
    "        # Is crowded?\n",
    "        iscrowd = 0\n",
    "\n",
    "        # Image ID\n",
    "        image_id = id_counter\n",
    "\n",
    "        # Segmentation\n",
    "        seg_image = io.imread(os.path.join(source_dataset_seg_loc, video_name, all_seg_frame_names[d]))/255\n",
    "        seg_coords_x, seg_coords_y = map(lambda x: list(x), np.where(seg_image==1))\n",
    "        seg_coords = []\n",
    "        for d, x in enumerate(seg_coords_x):\n",
    "            seg_coords.append(x)\n",
    "            seg_coords.append(seg_coords_y[d])\n",
    "\n",
    "        # Area\n",
    "        area = PolyArea(seg_coords_x, seg_coords_y)\n",
    "        \n",
    "        # Appending relevant info to the annotation section\n",
    "        minival2014['annotations'].append({'area': area, 'bbox': xywh, \n",
    "                                   'category_id': category_id,\n",
    "                                   'id': annot_id, 'image_id': image_id, 'iscrowd': iscrowd, 'segmentation': [seg_coords]})\n",
    "        id_counter += 1\n",
    "#         print(os.path.isfile(os.path.join(dataset_dir, source_dataset_name, train, video_name+\"/\", frame_name)))\n",
    "#         print(dataset_dir, target_dataset_name, frame_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images in segmentation directory are zero indexed and original image directory is one indexed.\n",
    "\n",
    "# dataset_dir = \"/home/mspr/Desktop/Mask_RCNN/Datasets/VOT2016/\"  # Will be changed with argparse, includes directories for video names and corresponding frames inside\n",
    "# train = \"train/\"                                                # train\n",
    "# dataset_seg_dir = \"GT_segmentation/\" # one indexed version for providing segmentation data. \n",
    "\n",
    "# # Date captured\n",
    "# dt = str(datetime.datetime.now())\n",
    "# date, time = dt.split()\n",
    "# time = time.split(\".\")[0]\n",
    "# date_captured = date+\" \"+time\n",
    "\n",
    "# # Copying to the COCO Dataset Directory in an appropiate format.\n",
    "# # Filename and ID will be collected from here.\n",
    "# target_dataset_dir = \"Datasets/coco/train2014/\"\n",
    "# idx = 600001\n",
    "# file_name = \"COCO_train2014_000000\"+str(idx)+\".jpg\"\n",
    "# image = io.imread(image_dir)\n",
    "# io.imsave(target_dataset_dir+file_name, image)\n",
    "\n",
    "# # License tag at random\n",
    "# license = np.random.randint(8)\n",
    "\n",
    "# # Getting image width and height\n",
    "# height = image.shape[1]\n",
    "# width = image.shape[0]\n",
    "\n",
    "# # URL Information is unknown\n",
    "# url = 'n/a'\n",
    "# # minival2014['images'].append({'date_captured': date_captured, 'file_name': file_name, \n",
    "# #                               'height': height, 'id': idx, 'license': license, 'flickr_url': url, \n",
    "# #                               'width': width, 'coco_url': url})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (minival2014['images'][-3:])\n",
    "# minival2014['images'].pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotations\n",
    "\n",
    "# def coco_bbox_creator(x, y):\n",
    "#     x = list(map(lambda x: float(x), x))\n",
    "#     y = list(map(lambda x: float(x), y))\n",
    "#     x_min = min(x)\n",
    "#     y_min = min(y)\n",
    "#     w = max(x) - x_min\n",
    "#     h = max(y) - y_min\n",
    "#     return [x_min, y_min, w, h]\n",
    "\n",
    "# # bbox\n",
    "# bbox_info_file = \"/home/mspr/Desktop/Mask_RCNN/Datasets/VOT2016/train/fish1/groundtruth.txt\"\n",
    "# with open(bbox_info_file) as f:\n",
    "#     all_bboxes = f.read().split()\n",
    "#     for bbox in all_bboxes[1:2]:\n",
    "#         coords = np.array(bbox.split(\",\")).reshape((-1, 2)) \n",
    "#         x, y = coords[:,0], coords[:,1]\n",
    "#         xywh = coco_bbox_creator(x, y)\n",
    "#         print(xywh)\n",
    "\n",
    "# # category id\n",
    "# # Create a dictionary where the keys will be video names and \n",
    "# # values will be category id's. Then calling this dictionary\n",
    "# # appropiately will output the category id. \n",
    "# # E.g --> dict['fish1'] = 91\n",
    "# category_id = 91\n",
    "\n",
    "# # id\n",
    "# annot_id = 300001\n",
    "    \n",
    "# # Is crowded?\n",
    "# iscrowd = 0\n",
    "\n",
    "# # Image ID\n",
    "# image_id = idx\n",
    "\n",
    "# # Segmentation\n",
    "# seg_image = io.imread(seg_image_dir)/255\n",
    "# seg_coords_x, seg_coords_y = map(lambda x: list(x), np.where(seg_image==1))\n",
    "# seg_coords = []\n",
    "# for d, x in enumerate(seg_coords_x):\n",
    "#     seg_coords.append(x)\n",
    "#     seg_coords.append(seg_coords_y[d])\n",
    "\n",
    "# # Area\n",
    "# def PolyArea(x,y):\n",
    "#     return 0.5*np.abs(np.dot(x,np.roll(y,1))-np.dot(y,np.roll(x,1)))\n",
    "\n",
    "# area = PolyArea(seg_coords_x, seg_coords_y)\n",
    "\n",
    "# minival2014['annotations'].append({'area': area, 'bbox': xywh, \n",
    "#                                    'category_id': category_id,\n",
    "#                                    'id': annot_id, 'image_id': idx, 'iscrowd': iscrowd, 'segmentation': [seg_coords]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minival2014['annotations'].pop()\n",
    "# print (minival2014['annotations'][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the data in memory and then writes them into a file. \n",
    "\n",
    "# from decimal import Decimal\n",
    "from json import encoder\n",
    "encoder.FLOAT_REPR = lambda o: format(o, '.2f')\n",
    "\n",
    "class MyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(MyEncoder, self).default(obj)\n",
    "\n",
    "with open(\"Datasets/coco/annotations/instances_minival2014.json\",\"w\") as f:\n",
    "    data = json.dumps(minival2014, cls=MyEncoder)\n",
    "    f.write(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
